{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Data:\n",
      "   Store  DayOfWeek       Date  Open  Promo StateHoliday  SchoolHoliday  \\\n",
      "0      1          5 2015-07-31     1      1            0              1   \n",
      "1      2          5 2015-07-31     1      1            0              1   \n",
      "2      3          5 2015-07-31     1      1            0              1   \n",
      "3      4          5 2015-07-31     1      1            0              1   \n",
      "4      5          5 2015-07-31     1      1            0              1   \n",
      "\n",
      "   CompetitionOpenSinceMonth  CompetitionOpenSinceYear  Promo2  ...  \\\n",
      "0                        9.0                    2008.0       0  ...   \n",
      "1                       11.0                    2007.0       1  ...   \n",
      "2                       12.0                    2006.0       1  ...   \n",
      "3                        9.0                    2009.0       0  ...   \n",
      "4                        4.0                    2015.0       0  ...   \n",
      "\n",
      "   StoreType_b  StoreType_c StoreType_d  Assortment_b  Assortment_c     Sales  \\\n",
      "0        False         True       False         False         False -0.132683   \n",
      "1        False        False       False         False         False  0.075373   \n",
      "2        False        False       False         False         False  0.659800   \n",
      "3        False         True       False         False          True  2.135414   \n",
      "4        False        False       False         False         False -0.247231   \n",
      "\n",
      "   Customers  CompetitionDistance  Days_to_Holiday  Days_After_Holiday  \n",
      "0  -0.168269            -0.539900        -1.734123             0.72171  \n",
      "1  -0.017540            -0.630746        -1.734123             0.72171  \n",
      "2   0.404499             1.129083        -1.734123             0.72171  \n",
      "3   1.862258            -0.624257        -1.734123             0.72171  \n",
      "4  -0.159656             3.177025        -1.734123             0.72171  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the datasets\n",
    "df_train = pd.read_csv('D:/week4 data/train.csv', low_memory=False)\n",
    "df_store = pd.read_csv('D:/week4 data/store.csv', low_memory=False)\n",
    "\n",
    "# Merge the datasets on the 'Store' column\n",
    "df_merged = pd.merge(df_train, df_store, on='Store')\n",
    "\n",
    "# Convert 'Date' column to datetime\n",
    "df_merged['Date'] = pd.to_datetime(df_merged['Date'])\n",
    "\n",
    "# Handle NaN values for numeric columns\n",
    "numeric_cols = df_merged.select_dtypes(include=['number']).columns\n",
    "df_merged[numeric_cols] = df_merged[numeric_cols].fillna(df_merged[numeric_cols].mean())\n",
    "\n",
    "# Extract new features from 'Date' column\n",
    "df_merged['Weekday'] = df_merged['Date'].dt.weekday\n",
    "df_merged['Is_Weekend'] = df_merged['Weekday'] >= 5\n",
    "df_merged['Month'] = df_merged['Date'].dt.month\n",
    "df_merged['Year'] = df_merged['Date'].dt.year\n",
    "\n",
    "# Define holidays (Example dates for Christmas and New Year)\n",
    "holidays = pd.to_datetime(['2013-12-25', '2014-12-25', '2015-12-25', '2014-01-01', '2015-01-01'])\n",
    "\n",
    "# Calculate number of days to the next holiday\n",
    "df_merged['Days_to_Holiday'] = df_merged['Date'].apply(lambda x: (holidays - x).min().days)\n",
    "\n",
    "# Calculate number of days after the last holiday\n",
    "df_merged['Days_After_Holiday'] = df_merged['Date'].apply(lambda x: (x - holidays[holidays <= x].max()).days)\n",
    "\n",
    "# Identify the beginning, mid, and end of the month\n",
    "df_merged['Month_Period'] = pd.cut(df_merged['Date'].dt.day, bins=[0, 10, 20, 31], labels=['Beginning', 'Mid', 'End'])\n",
    "\n",
    "# Convert categorical columns to numeric using one-hot encoding\n",
    "df_merged = pd.get_dummies(df_merged, columns=['Month_Period', 'StoreType', 'Assortment'], drop_first=True)\n",
    "\n",
    "# Select features for scaling\n",
    "features_to_scale = df_merged[['Sales', 'Customers', 'CompetitionDistance', 'Days_to_Holiday', 'Days_After_Holiday']]\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the data\n",
    "scaled_features = scaler.fit_transform(features_to_scale)\n",
    "\n",
    "# Convert scaled features to DataFrame\n",
    "scaled_df = pd.DataFrame(scaled_features, columns=features_to_scale.columns)\n",
    "\n",
    "# Combine scaled features with the rest of the dataset\n",
    "df_preprocessed = df_merged.drop(columns=features_to_scale.columns).reset_index(drop=True)\n",
    "df_preprocessed = pd.concat([df_preprocessed, scaled_df], axis=1)\n",
    "\n",
    "print(\"Preprocessed Data:\")\n",
    "print(df_preprocessed.head())\n",
    "\n",
    "# Save the preprocessed data to a CSV file\n",
    "df_preprocessed.to_csv('D:/week4 data/preprocessed_data.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the preprocessed data\n",
    "df_preprocessed = pd.read_csv('D:/week4 data/preprocessed_data.csv')\n",
    "\n",
    "# Drop non-numeric columns\n",
    "df_preprocessed = df_preprocessed.drop(columns=['Date', 'StateHoliday', 'PromoInterval'])\n",
    "\n",
    "# Define features and target variable\n",
    "X = df_preprocessed.drop(columns=['Sales'])\n",
    "y = df_preprocessed['Sales']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Scale features\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))  # Random Forest Regressor\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(pipeline, 'D:/week4 data/random_forest_pipeline.pkl')\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "\n",
    "# Visualize the results (Optional)\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('Actual Sales')\n",
    "plt.ylabel('Predicted Sales')\n",
    "plt.title('Actual vs Predicted Sales')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ebcli-virtual-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
